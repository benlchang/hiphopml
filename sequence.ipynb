{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mediapipe in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (0.10.14)\n",
      "Requirement already satisfied: absl-py in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from mediapipe) (23.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (0.4.30)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (0.4.30)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from mediapipe) (4.25.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (0.4.7)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from jax->mediapipe) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from jax->mediapipe) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from jax->mediapipe) (1.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->mediapipe) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->mediapipe) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\benlc\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from matplotlib->mediapipe) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\benlc\\hiphopml\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "######## install dependencies ########\n",
    "\n",
    "%pip install numpy opencv-python tensorflow\n",
    "%pip install --user mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## import and set up opencv, mediapipe ########\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import mediapipe as media\n",
    "\n",
    "mp_drawing_styles = media.solutions.drawing_styles\n",
    "mp_drawing = media.solutions.drawing_utils\n",
    "mp_pose = media.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track figure poses and generate motion history images from webcam feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## set motion history image parameters ########\n",
    "\n",
    "MHI_DURATION = 4\n",
    "THRESHOLD = 32\n",
    "MAX_TIME_DELTA = 2.0\n",
    "MIN_TIME_DELTA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## image resize method ########\n",
    "\n",
    "def preprocess_MHI_frame(frame):\n",
    "    H, W = frame.shape[0], frame.shape[1]\n",
    "    resizeH = 600\n",
    "    resizeW = int((W / H) * resizeH)\n",
    "    \n",
    "    resize_image = cv2.resize(frame, (resizeW, resizeH))\n",
    "    #input_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR)    #makes you blue!\n",
    "    #gray_image = cv2.cvtColor(resize_image, cv2.COLOR_BGR2GRAY)\n",
    "    return resize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benlc\\hiphopml\\env\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sequential model 'sequential_1' has already been configured to use input shape (None, 256, 256). You cannot build it with input_shape (1, 256, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m     resize \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(cv2\u001b[38;5;241m.\u001b[39mresize(mhi, (\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m)), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(resize\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     74\u001b[0m     delay \u001b[38;5;241m=\u001b[39m timestamp \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m     76\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMotion History Feed\u001b[39m\u001b[38;5;124m'\u001b[39m, mhi)\n",
      "File \u001b[1;32mc:\\Users\\benlc\\hiphopml\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\benlc\\hiphopml\\env\\Lib\\site-packages\\keras\\src\\models\\sequential.py:166\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer):\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape \u001b[38;5;241m!=\u001b[39m input_shape:\n\u001b[1;32m--> 166\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    167\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has already been \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigured to use input shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    169\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. You cannot build it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith input_shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m         )\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcompute_dtype\n",
      "\u001b[1;31mValueError\u001b[0m: Sequential model 'sequential_1' has already been configured to use input shape (None, 256, 256). You cannot build it with input_shape (1, 256, 256)"
     ]
    }
   ],
   "source": [
    "########    PROCESS LIVE WEBCAM DATA    ########\n",
    "#   MHI of pose data\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "H, W = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "W = int(W / H * 600)\n",
    "\n",
    "motion_history = np.zeros((600, W), np.float32)\n",
    "\n",
    "index = 0\n",
    "delay = 0.0\n",
    "init_timestamp = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "datadir = './data/cabbagepatch/'\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.25, min_tracking_confidence=0.25) as pose:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    prev_frame = 0\n",
    "    if ret:\n",
    "        prev_initframe = preprocess_MHI_frame(frame)\n",
    "        prev_results = pose.process(prev_initframe)\n",
    "\n",
    "        prev_frame = np.zeros(prev_initframe.shape)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(\n",
    "            prev_frame,\n",
    "            prev_results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "        \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"error reading video feed\")\n",
    "            break\n",
    "\n",
    "        curr_initframe = preprocess_MHI_frame(frame)\n",
    "        pose_results = pose.process(curr_initframe)\n",
    "\n",
    "        curr_frame = np.zeros(curr_initframe.shape)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(\n",
    "            curr_frame,\n",
    "            pose_results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "\n",
    "        silhouette = cv2.absdiff(curr_frame, prev_frame).astype(np.uint8)\n",
    "        silhouette = cv2.cvtColor(silhouette, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        ret, motion_mask = cv2.threshold(silhouette, THRESHOLD, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "        timestamp = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "        motion_history[motion_mask == 1] = timestamp\n",
    "\n",
    "        mhi = np.uint8(np.clip(1 - (timestamp - motion_history) / MHI_DURATION, 0, 1) * 255)\n",
    "        \n",
    "        # if timestamp - init_timestamp > 10.0 and timestamp > delay:\n",
    "        #     cv2.imwrite(datadir + f'{index}.png', mhi)\n",
    "        #     index += 1\n",
    "        #     delay = timestamp + 1.0\n",
    "        #     if index >= 32:\n",
    "        #         break\n",
    "        \n",
    "        # FIGURE OUT HOW TO CONVERT VIDEO FEED INTO TRAINABLE DATA\n",
    "\n",
    "        if timestamp > delay:\n",
    "            resize = cv2.resize(mhi, (256,256,3))\n",
    "            print(resize.shape)\n",
    "            print(model.predict(resize))\n",
    "            delay = timestamp + 1.0\n",
    "\n",
    "        cv2.imshow('Motion History Feed', mhi)\n",
    "\n",
    "        prev_frame = curr_frame\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pose coordinate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nose {'x': 0.621558427810669, 'y': 0.08921728283166885, 'z': -0.5160354375839233, 'vis': 0.9999528527259827}\n",
      "left_eye_inner {'x': 0.6334375739097595, 'y': 0.07345728576183319, 'z': -0.484919011592865, 'vis': 0.9999215602874756}\n",
      "left_eye {'x': 0.6378164291381836, 'y': 0.07472570985555649, 'z': -0.4850243031978607, 'vis': 0.9999128580093384}\n",
      "left_eye_outer {'x': 0.6419649720191956, 'y': 0.07605085521936417, 'z': -0.4851114749908447, 'vis': 0.999923586845398}\n",
      "right_eye_inner {'x': 0.6195680499076843, 'y': 0.0685989037156105, 'z': -0.4895278811454773, 'vis': 0.9999054074287415}\n",
      "right_eye {'x': 0.6142794489860535, 'y': 0.06626370549201965, 'z': -0.4896296560764313, 'vis': 0.9998775124549866}\n",
      "right_eye_outer {'x': 0.6092092990875244, 'y': 0.06397171318531036, 'z': -0.48960861563682556, 'vis': 0.9998661875724792}\n",
      "left_ear {'x': 0.645785391330719, 'y': 0.0829315185546875, 'z': -0.2932945787906647, 'vis': 0.9998888373374939}\n",
      "right_ear {'x': 0.6009838581085205, 'y': 0.06389220803976059, 'z': -0.3177655041217804, 'vis': 0.9997892379760742}\n",
      "mouth_left {'x': 0.6256917715072632, 'y': 0.10819751769304276, 'z': -0.4447471499443054, 'vis': 0.9999687075614929}\n",
      "mouth_right {'x': 0.6098979115486145, 'y': 0.10041282325983047, 'z': -0.45215922594070435, 'vis': 0.999962329864502}\n",
      "left_shoulder {'x': 0.6493323445320129, 'y': 0.21024011075496674, 'z': -0.1606559306383133, 'vis': 0.9999806880950928}\n",
      "right_shoulder {'x': 0.5380613207817078, 'y': 0.12587593495845795, 'z': -0.1946912705898285, 'vis': 0.9999354481697083}\n",
      "left_elbow {'x': 0.7023911476135254, 'y': 0.338627427816391, 'z': -0.1837303191423416, 'vis': 0.9964820146560669}\n",
      "right_elbow {'x': 0.4533859193325043, 'y': 0.1792890876531601, 'z': -0.2460217922925949, 'vis': 0.9890568852424622}\n",
      "left_wrist {'x': 0.6528295278549194, 'y': 0.39082100987434387, 'z': -0.4268823266029358, 'vis': 0.9877458810806274}\n",
      "right_wrist {'x': 0.3940719664096832, 'y': 0.1438639760017395, 'z': -0.524735689163208, 'vis': 0.9874544739723206}\n",
      "left_pinky {'x': 0.6350216865539551, 'y': 0.41391676664352417, 'z': -0.4887162446975708, 'vis': 0.9635221362113953}\n",
      "right_pinky {'x': 0.37885624170303345, 'y': 0.11449187248945236, 'z': -0.5909318327903748, 'vis': 0.9794825911521912}\n",
      "left_index {'x': 0.6273606419563293, 'y': 0.40009644627571106, 'z': -0.507577657699585, 'vis': 0.964292049407959}\n",
      "right_index {'x': 0.38327381014823914, 'y': 0.11200836300849915, 'z': -0.6283041834831238, 'vis': 0.9817368388175964}\n",
      "left_thumb {'x': 0.6303392648696899, 'y': 0.3892706334590912, 'z': -0.4383939504623413, 'vis': 0.9560326337814331}\n",
      "right_thumb {'x': 0.388675719499588, 'y': 0.1252284049987793, 'z': -0.5484094023704529, 'vis': 0.9770404100418091}\n",
      "left_hip {'x': 0.5678485035896301, 'y': 0.4223654568195343, 'z': 0.052931562066078186, 'vis': 0.9995967745780945}\n",
      "right_hip {'x': 0.49814099073410034, 'y': 0.4078102111816406, 'z': -0.05306166782975197, 'vis': 0.9995025396347046}\n",
      "left_knee {'x': 0.6068205237388611, 'y': 0.5715246200561523, 'z': 0.013647487387061119, 'vis': 0.971367359161377}\n",
      "right_knee {'x': 0.45874837040901184, 'y': 0.5878102779388428, 'z': -0.06299544125795364, 'vis': 0.9835042357444763}\n",
      "left_ankle {'x': 0.6151605844497681, 'y': 0.7593894600868225, 'z': 0.2689381539821625, 'vis': 0.97542804479599}\n",
      "right_ankle {'x': 0.42332690954208374, 'y': 0.7434566020965576, 'z': 0.21410317718982697, 'vis': 0.9811601638793945}\n",
      "left_heel {'x': 0.598787784576416, 'y': 0.791541576385498, 'z': 0.2869493067264557, 'vis': 0.9293818473815918}\n",
      "right_heel {'x': 0.4173694849014282, 'y': 0.7572775483131409, 'z': 0.23211684823036194, 'vis': 0.781170666217804}\n",
      "left_foot_index {'x': 0.6734011769294739, 'y': 0.807495653629303, 'z': 0.13560205698013306, 'vis': 0.968251645565033}\n",
      "right_foot_index {'x': 0.438899964094162, 'y': 0.8084189295768738, 'z': 0.043795324862003326, 'vis': 0.9573058485984802}\n"
     ]
    }
   ],
   "source": [
    "########    match pose landmarks to coordinates     ########\n",
    "\n",
    "pose_indices = ['nose', \n",
    "                'left_eye_inner', 'left_eye', 'left_eye_outer', \n",
    "                'right_eye_inner', 'right_eye', 'right_eye_outer',\n",
    "                'left_ear', 'right_ear',\n",
    "                'mouth_left', 'mouth_right',\n",
    "                'left_shoulder', 'right_shoulder',\n",
    "                'left_elbow', 'right_elbow',\n",
    "                'left_wrist', 'right_wrist',\n",
    "                'left_pinky', 'right_pinky',\n",
    "                'left_index', 'right_index',\n",
    "                'left_thumb', 'right_thumb',\n",
    "                'left_hip', 'right_hip',\n",
    "                'left_knee', 'right_knee',\n",
    "                'left_ankle', 'right_ankle',\n",
    "                'left_heel', 'right_heel',\n",
    "                'left_foot_index', 'right_foot_index']\n",
    "\n",
    "def setNewCoords(landmark):\n",
    "    new_coords = [{\n",
    "                'x': point.x,\n",
    "                'y': point.y,\n",
    "                'z': point.z,\n",
    "                'vis': point.visibility\n",
    "                }   \n",
    "                for point in landmark]\n",
    "\n",
    "    keypoints = {}\n",
    "    for i in range(len(pose_indices)):\n",
    "        keypoints[pose_indices[i]] = new_coords[i]\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "keypoints = setNewCoords(pose_landmarks.landmark)\n",
    "for key in keypoints.keys():\n",
    "    if keypoints[key]['vis'] > 0.5:\n",
    "        print(key, keypoints[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body-ang 0.2968405428715714\n",
      "LA-ang 1.9901597463662961\n",
      "RA-ang 2.040441019913823\n",
      "LL-ang -2.9303926250519243\n",
      "RL-ang 3.1332781667736183\n",
      "SR-ang 0.02653235396175402\n",
      "SR-mp 0.020781755447387695\n",
      "F-depth 0.0\n",
      "F-height 0.015932857990264893\n",
      "LF-ang -2.3055504388264145\n",
      "RF-ang -2.682542757841427\n"
     ]
    }
   ],
   "source": [
    "########    calculate parameter values     ########\n",
    "\n",
    "def calcParamValues(keypoints):\n",
    "    #hip midpoint\n",
    "    hip_midpoint = (keypoints['right_hip']['x'] - keypoints['left_hip']['x']) / 2\n",
    "\n",
    "    #calculate cartesian distance between two points\n",
    "    def calculateDistance(x, y):\n",
    "        return np.sqrt(x ** 2 + y ** 2)\n",
    "\n",
    "    #calculate angle created by two cartesian vectors\n",
    "    #   negative angles : bend outward, i.e. gotta piss\n",
    "    #   positive angles : bend inward, i.e. sumo squat\n",
    "    def calculateAngle(A, B, C = None):\n",
    "        direction = 1\n",
    "        if not C:\n",
    "            C = {'x': 1, 'y': 0}\n",
    "        elif abs(B['x'] - hip_midpoint) < abs(C['x'] - hip_midpoint):\n",
    "            direction = -1\n",
    "\n",
    "        vecBA, vecBC = [A['x'] - B['x'], A['y'] - B['y']], [C['x'] - B['x'], C['y'] - B['y']]\n",
    "        dot_product = vecBA[0] * vecBC[0] + vecBA[1] * vecBC[1]\n",
    "        magBA, magBC = calculateDistance(vecBA[0], vecBA[1]), calculateDistance(vecBC[0], vecBC[1])\n",
    "        return np.arccos(dot_product / (magBA * magBC)) * direction\n",
    "\n",
    "    #calculate body facing\n",
    "    # -pi : facing to the right\n",
    "    #  0  : facing the camera\n",
    "    #  pi : facing to the left\n",
    "    shoulder_depthdiff = keypoints['left_shoulder']['z'] - keypoints['right_shoulder']['z']\n",
    "    shoulder_widthdiff = keypoints['left_shoulder']['x'] - keypoints['right_shoulder']['x']\n",
    "    body_angle = np.arctan(shoulder_depthdiff / shoulder_widthdiff)\n",
    "\n",
    "    #calculate arm angles\n",
    "    leftarm_angle = calculateAngle(keypoints['left_shoulder'], keypoints['left_elbow'], keypoints['left_wrist']) \n",
    "    rightarm_angle = calculateAngle(keypoints['right_shoulder'], keypoints['right_elbow'], keypoints['right_wrist']) \n",
    "    leftleg_angle = calculateAngle(keypoints['left_hip'], keypoints['left_knee'], keypoints['left_ankle'])\n",
    "    rightleg_angle = calculateAngle(keypoints['right_hip'], keypoints['right_knee'], keypoints['right_ankle'])\n",
    "\n",
    "    #calculate shoulder dimensions relative to hips\n",
    "    shoulder_angle = calculateAngle(keypoints['left_shoulder'], keypoints['right_shoulder'])\n",
    "    hip_angle = calculateAngle(keypoints['left_hip'], keypoints['right_hip'])\n",
    "    shoulder_relativeangle = shoulder_angle - hip_angle\n",
    "\n",
    "    shoulder_midpoint = (keypoints['right_shoulder']['x'] - keypoints['left_shoulder']['x']) / 2\n",
    "    shoulder_relativemidpoint = abs(shoulder_midpoint - hip_midpoint)\n",
    "\n",
    "    #calculate foot dimensions relative to each other\n",
    "    foot_depthdiff = keypoints['left_ankle']['z'] - keypoints['left_ankle']['z']\n",
    "    foot_heightdiff = keypoints['left_ankle']['y'] - keypoints['right_ankle']['y']\n",
    "\n",
    "    #calculate angle of the foot\n",
    "    # using knee-heel-toe angle to describe foot direction\n",
    "    leftfoot_angle = calculateAngle(keypoints['left_knee'], keypoints['left_heel'], keypoints['left_foot_index'])\n",
    "    rightfoot_angle = calculateAngle(keypoints['right_knee'], keypoints['right_heel'], keypoints['right_foot_index'])\n",
    "\n",
    "    profile = {'body-ang': body_angle, \n",
    "               'LA-ang': leftarm_angle, 'RA-ang': rightarm_angle, \n",
    "               'LL-ang': leftleg_angle, 'RL-ang': rightleg_angle,\n",
    "            'SR-ang': shoulder_relativeangle, 'SR-mp': shoulder_relativemidpoint,\n",
    "            'F-depth': foot_depthdiff, 'F-height': foot_heightdiff,\n",
    "            'LF-ang': leftfoot_angle, 'RF-ang': rightfoot_angle}\n",
    "    \n",
    "    return profile\n",
    "\n",
    "parameterValues = calcParamValues(keypoints)\n",
    "for key in parameterValues.keys():\n",
    "    print(key, parameterValues[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model with Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## import tensorflow + keras ########\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 files belonging to 4 classes.\n",
      "(8, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "######## preprocess image data from directories ########\n",
    "data = tf.keras.utils.image_dataset_from_directory('data', batch_size=8)\n",
    "\n",
    "data = data.map(lambda x,y: (x/255, y))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "\n",
    "print(batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .7)\n",
    "val_size = int(len(data) * .2) + 1\n",
    "test_size = int(len(data) * .1)\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127008</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,128,576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127008\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m8,128,576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,131,124</span> (31.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,131,124\u001b[0m (31.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,131,124</span> (31.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,131,124\u001b[0m (31.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## set up model and convolutional layers ########\n",
    "model = Sequential()\n",
    "\n",
    "#16 filters\n",
    "model.add(Conv2D(16, (2, 2), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#32 filters\n",
    "model.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "#narrow down to 4 identifiers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.3855 - loss: 3.0031 - val_accuracy: 0.7812 - val_loss: 0.5187\n",
      "Epoch 2/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7268 - loss: 0.5164 - val_accuracy: 0.8438 - val_loss: 0.2740\n",
      "Epoch 3/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9287 - loss: 0.2154 - val_accuracy: 1.0000 - val_loss: 0.1336\n",
      "Epoch 4/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0756 - val_accuracy: 1.0000 - val_loss: 0.0305\n",
      "Epoch 5/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0171 - val_accuracy: 1.0000 - val_loss: 0.0096\n",
      "Epoch 6/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 7/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 8/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 9/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 4.1926e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 4.7393e-04 - val_accuracy: 1.0000 - val_loss: 3.4315e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 3.2016e-04 - val_accuracy: 1.0000 - val_loss: 2.2673e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 3.4453e-04 - val_accuracy: 1.0000 - val_loss: 2.0847e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 1.8647e-04 - val_accuracy: 1.0000 - val_loss: 1.6329e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.7980e-04 - val_accuracy: 1.0000 - val_loss: 7.2689e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 1.6724e-04 - val_accuracy: 1.0000 - val_loss: 7.9465e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 1.0366e-04 - val_accuracy: 1.0000 - val_loss: 1.1132e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 9.8176e-05 - val_accuracy: 1.0000 - val_loss: 5.7770e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 6.5861e-05 - val_accuracy: 1.0000 - val_loss: 4.7636e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 4.8714e-05 - val_accuracy: 1.0000 - val_loss: 4.0402e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 6.9293e-05 - val_accuracy: 1.0000 - val_loss: 6.4580e-05\n"
     ]
    }
   ],
   "source": [
    "######## train  #######\n",
    "\n",
    "train_size = int(len(data) * .7)\n",
    "val_size = int(len(data) * .2) + 1\n",
    "test_size = int(len(data) * .1)\n",
    "\n",
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)\n",
    "\n",
    "logdir = 'logs'\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benlc\\hiphopml\\env\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "[[0. 0. 1. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "[[1.0000000e+00 3.9761057e-37 3.7550594e-09 0.0000000e+00]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[[0. 1. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "[[1. 0. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "[[1. 0. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "[[0. 1. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "[[0. 1. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "[[0. 1. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "[[0. 1. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[[0. 1. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "[[1. 0. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[[1. 0. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "[[1. 0. 0. 0.]]\n",
      "(256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[[1.0000000e+00 1.1130501e-10 0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "H, W = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "W = int(W / H * 600)\n",
    "\n",
    "motion_history = np.zeros((600, W), np.float32)\n",
    "\n",
    "index = 0\n",
    "delay = 15.0\n",
    "init_timestamp = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "\n",
    "moves_map = ['bart simpson', 'biz markie', 'cabbage patch', 'reject']\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.25, min_tracking_confidence=0.25) as pose:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    prev_frame = 0\n",
    "    if ret:\n",
    "        prev_initframe = preprocess_MHI_frame(frame)\n",
    "        prev_results = pose.process(prev_initframe)\n",
    "\n",
    "        prev_frame = np.zeros(prev_initframe.shape)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(\n",
    "            prev_frame,\n",
    "            prev_results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "        \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"error reading video feed\")\n",
    "            break\n",
    "\n",
    "        curr_initframe = preprocess_MHI_frame(frame)\n",
    "        pose_results = pose.process(curr_initframe)\n",
    "\n",
    "        curr_frame = np.zeros(curr_initframe.shape)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(\n",
    "            curr_frame,\n",
    "            pose_results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "\n",
    "        silhouette = cv2.absdiff(curr_frame, prev_frame).astype(np.uint8)\n",
    "        silhouette = cv2.cvtColor(silhouette, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        ret, motion_mask = cv2.threshold(silhouette, THRESHOLD, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "        timestamp = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "        motion_history[motion_mask == 1] = timestamp\n",
    "\n",
    "        mhi = np.uint8(np.clip(1 - (timestamp - motion_history) / MHI_DURATION, 0, 1) * 255)\n",
    "\n",
    "        if timestamp > delay:\n",
    "            resize = cv2.resize(mhi, (256,256))\n",
    "            resize_rgb = cv2.cvtColor(resize, cv2.COLOR_GRAY2RGB)\n",
    "            print(resize_rgb.shape)\n",
    "            print(model.predict(np.expand_dims(resize_rgb, 0)))\n",
    "            delay = timestamp + 3.0\n",
    "\n",
    "        cv2.imshow('Motion History Feed', mhi)\n",
    "\n",
    "        prev_frame = curr_frame\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/danceid.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./models/danceid.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
